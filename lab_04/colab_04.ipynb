{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yaWalgW_d7j"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 1000px\" src=\"banner.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dojtwAh1Ww1B"
   },
   "source": [
    "#### <img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"hsg_logo.png\">\n",
    "\n",
    "##  Lab 04 - Artificial Neural Networks (ANNs)\n",
    "\n",
    "GSERM Summer School 2024, Deep Learning: Fundamentals and Applications, University of St. Gallen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5b1H7xuj_d7k"
   },
   "source": [
    "The lab environment is based on Jupyter Notebooks (https://jupyter.org), which provide an interactive platform for performing a variety of statistical evaluations and data analyses. In this lab, we will learn how to implement, train, and apply our first **Artificial Neural Network (ANN)** using a Python library named `PyTorch`. The `PyTorch` library is an open-source machine learning library for Python, used for a variety of applications such as image classification and natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aR4Ywe2HWw1M"
   },
   "source": [
    "Artificial Neural Networks, inspired by the human brain, have a rich history dating back to the 1940s. Key figures such as *Warren McCulloch* and *Walter Pitts*, who introduced **the first computational model for neural networks**, and *Frank Rosenblatt*, who developed the **perceptron algorithm** in the 1950s, played pivotal roles in the evolution of ANNs. These networks are designed to recognize patterns and make decisions. In this lab, we will delve into the fascinating world of neural networks and harness their power to classify images of fashion articles from the **Fashion-MNIST** dataset, a popular dataset used in machine learning for benchmarking models.\n",
    "\n",
    "The figure below illustrates a high-level view of the machine-learning process we aim to establish in this lab:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgQ_ksmaWw1N"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 700px\" src=\"./classification.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-9LY1AjWw1O"
   },
   "source": [
    "As always, please don't hesitate to ask any questions during the lab, post them in our CANVAS (StudyNet) forum (https://learning.unisg.ch), or send us an email using the course email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aut1dJXmWw1O"
   },
   "source": [
    "## 1. Lab Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tb0svb4Ww1O"
   },
   "source": [
    "After today's lab, you should be able to:\n",
    "\n",
    "> 1. **Understand Neural Network Design:** Learn the fundamental concepts and architectural design of artificial neural networks.\n",
    "> 2. **Implement and Train a Neural Network:** Gain hands-on experience with PyTorch to build and train a neural network model.\n",
    "> 3. **Apply Neural Networks for Image Classification:** Use neural networks to classify images of fashion articles from the Fashion-MNIST dataset.\n",
    "> 4. **Evaluate and Interpret Model Performance:** Evaluate the network's classification results using accuracy metrics and interpret the confusion matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svq48yIQt8lM"
   },
   "source": [
    "Before we start let's watch a motivational video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyE587hOt8lN"
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "# Official Intro | GTC 2017 | I AM AI\"\n",
    "# YouTubeVideo('SUNPrR4o5ZA', width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ks081EJEWw1P"
   },
   "source": [
    "## 2. Setup of the Jupyter Notebook Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdmhjYHFWw1P"
   },
   "source": [
    "Similar to the previous labs, we need to import a few Python libraries for data analysis and visualization. We will primarily use `PyTorch`, `Numpy`, `Scikit-Learn`, `Matplotlib`, `Seaborn`, and a few utility libraries throughout this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rDvIKj-Ww1P"
   },
   "outputs": [],
   "source": [
    "# import standard python libraries\n",
    "import os, urllib, io\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heUZY7dgWw1Q"
   },
   "source": [
    "Import the Python machine / deep learning libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RTb4Mc1Ww1Q"
   },
   "outputs": [],
   "source": [
    "# import the PyTorch deep learning libary\n",
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRpZfSImWw1R"
   },
   "source": [
    "Import the sklearn classification metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJ180J4sWw1R"
   },
   "outputs": [],
   "source": [
    "# import sklearn classification evaluation library\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tatoV81Ww1R"
   },
   "source": [
    "Import Python plotting libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTSNWwejWw1R"
   },
   "outputs": [],
   "source": [
    "# import matplotlib, seaborn, and PIL data visualization libary\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g83bVkFrWw1S"
   },
   "source": [
    "Enable notebook matplotlib inline plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0MKI98CWw1S"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DM3LiXwWWw1S"
   },
   "source": [
    "Import `Google's GDrive` connector and mount your GDrive directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptQU8CeEWw1S"
   },
   "outputs": [],
   "source": [
    "# import the Google Colab GDrive connector\n",
    "from google.colab import drive\n",
    "\n",
    "# mount GDrive inside the Colab notebook\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I81E5iJOwR6x"
   },
   "source": [
    "Create a structure of Colab Notebook sub-directories inside of `GDrive` to store the data and the trained neural network models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq5F-BV1wSXL"
   },
   "outputs": [],
   "source": [
    "# create Colab Notebooks directory\n",
    "notebook_directory = '/content/drive/MyDrive/Colab Notebooks'\n",
    "if not os.path.exists(notebook_directory): os.makedirs(notebook_directory)\n",
    "\n",
    " # create data sub-directory inside the Colab Notebooks directory\n",
    "data_directory = '/content/drive/MyDrive/Colab Notebooks/data_fmnist'\n",
    "if not os.path.exists(data_directory): os.makedirs(data_directory)\n",
    "\n",
    " # create models sub-directory inside the Colab Notebooks directory\n",
    "models_directory = '/content/drive/MyDrive/Colab Notebooks/models_fmnist'\n",
    "if not os.path.exists(models_directory): os.makedirs(models_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32BCRqyA5cD5"
   },
   "source": [
    "Set a random `seed` value to obtain reproducible results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3cPTu1R5cmj"
   },
   "outputs": [],
   "source": [
    "# init deterministic seed\n",
    "seed_value = 1234\n",
    "np.random.seed(seed_value) # set numpy seed\n",
    "torch.manual_seed(seed_value) # set pytorch seed CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHMs9Gf0wakv"
   },
   "source": [
    "Google Colab provides free GPUs for running notebooks. However, if you execute this notebook as is, it will use your device's CPU. To run the lab on a GPU, go to `Runtime` > `Change runtime type` and set the Runtime type to `GPU` in the drop-down menu. Running this lab on a CPU is fine, but you will find that GPU computing is faster. *CUDA* indicates that the lab is being run on a GPU.\n",
    "\n",
    "Enable GPU computing by setting the device flag and initializing a CUDA seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fl2UHzshwdyk"
   },
   "outputs": [],
   "source": [
    "# set cpu or gpu enabled device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
    "\n",
    "# init deterministic GPU seed\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "\n",
    "# log type of device enabled\n",
    "print('[LOG] notebook with {} computation enabled'.format(str(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47HnxJHswf05"
   },
   "source": [
    "Let's determine if we have access to a GPU provided by environments such as `Google Colab`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "907R1nhVwhXb"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyqnqndjWw1S"
   },
   "source": [
    "## 3. Dataset Download and Data Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgyKo34eWw1T"
   },
   "source": [
    "The **Fashion-MNIST database** is a large dataset of Zalando articles commonly used for training various image processing systems. The database is widely used for training and testing in the field of machine learning. Let's take a brief look at a few sample images from the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-q9TexBXWw1T"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 700px; height: 300px\" src=\"./FashionMNIST.png\">\n",
    "\n",
    "Source: https://www.kaggle.com/c/insar-fashion-mnist-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YEOHPO5Ww1T"
   },
   "source": [
    "Further details on the dataset can be obtained from Zalando Research's [GitHub page](https://github.com/zalandoresearch/fashion-mnist)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_B6cw9iEWw1T"
   },
   "source": [
    "The **Fashion-MNIST database** is an image dataset of Zalando's article images, consisting of **70,000 images** in total. The dataset is divided into **60,000 training examples** and **10,000 evaluation examples**. Each example is a **28x28 grayscale image**, associated with a **label from 10 classes**. Zalando created this dataset to replace the popular **MNIST** handwritten digits dataset. It is a useful addition as it is a bit more complex but still very easy to use. It shares the same image size and train/test split structure as MNIST, making it a drop-in replacement. It requires minimal efforts in preprocessing and formatting the distinct images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igSTsQMKWw1U"
   },
   "source": [
    "Let's download, transform and inspect the training images of the dataset. Therefore, let's first define the directory in which we aim to store the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfCn1e8MWw1V"
   },
   "outputs": [],
   "source": [
    "train_path = data_directory + '/train_fmnist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4fUsNeLWw1V"
   },
   "source": [
    "Now, let's download the training data accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-GZL31YWw1W"
   },
   "outputs": [],
   "source": [
    "# define pytorch transformation into tensor format\n",
    "transf = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "# download and transform training images\n",
    "fashion_mnist_train_data = torchvision.datasets.FashionMNIST(root=train_path, train=True, transform=transf, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaLuUXc4Ww1W"
   },
   "source": [
    "Verify the number of training images downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmRdyfxFWw1W"
   },
   "outputs": [],
   "source": [
    "# determine the number of training data images\n",
    "len(fashion_mnist_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtbIaCpLWw1W"
   },
   "source": [
    "Next, let's inspect a few of the downloaded training images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gAtYOeUPWw1X"
   },
   "outputs": [],
   "source": [
    "# select and set a (random) image id\n",
    "image_id = 3000\n",
    "\n",
    "# retrieve image exhibiting the image id\n",
    "fashion_mnist_train_data[image_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfUMS402Ww1X"
   },
   "source": [
    "Ok, that doesn't seem right. Let's now separate the image from its label information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDzFFyZfWw1X"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_train_image, fashion_mnist_train_label = fashion_mnist_train_data[image_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SSorDiP_uFc"
   },
   "source": [
    "We can verify the label of our selected image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "weOc_Ceb_5dU"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctD4Dl0C_7RE"
   },
   "source": [
    "Ok, we know that the numerical label is 6. Each image is associated with a label from 0 to 9, representing one of the fashion items. So what does 6 mean? Is it a bag? A pullover? \n",
    "\n",
    "The order of the classes can be found on Zalando Research's [GitHub page](https://github.com/zalandoresearch/fashion-mnist). We need to map each numerical label to its fashion item, which will be useful throughout the lab:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmzSMz1FASrm"
   },
   "outputs": [],
   "source": [
    "fashion_classes = {0: 'T-shirt/top',\n",
    "                    1: 'Trouser',\n",
    "                    2: 'Pullover',\n",
    "                    3: 'Dress',\n",
    "                    4: 'Coat',\n",
    "                    5: 'Sandal',\n",
    "                    6: 'Shirt',\n",
    "                    7: 'Sneaker',\n",
    "                    8: 'Bag',\n",
    "                    9: 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDvW1PUdKn3a"
   },
   "source": [
    "So, we can determine the fashion item that the label represents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8KrM8rfKnHh"
   },
   "outputs": [],
   "source": [
    "fashion_classes[fashion_mnist_train_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JozKTGsCWw1X"
   },
   "source": [
    "Great, let's now visually inspect our sample image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D80b3WkWWw1Y"
   },
   "outputs": [],
   "source": [
    "# define tensor to image transformation\n",
    "trans = torchvision.transforms.ToPILImage()\n",
    "\n",
    "# set image plot title \n",
    "plt.title('Example: {}, Label: {}'.format(str(image_id), fashion_classes[fashion_mnist_train_label]))\n",
    "\n",
    "# plot mnist handwritten digit sample\n",
    "plt.imshow(trans(fashion_mnist_train_image), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5fmhiuzWw1Y"
   },
   "source": [
    "Fantastic, right? Let's now define the directory in which we aim to store the evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8G3eQFy3Ww1b"
   },
   "outputs": [],
   "source": [
    "eval_path = data_directory + '/eval_fmnist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNNTmyI7Ww1b"
   },
   "source": [
    "And download the evaluation data accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvIBdhlPWw1b"
   },
   "outputs": [],
   "source": [
    "# define pytorch transformation into tensor format\n",
    "transf = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "# download and transform training images\n",
    "fashion_mnist_eval_data = torchvision.datasets.FashionMNIST(root=eval_path, train=False, transform=transf, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4skfCFEfWw1c"
   },
   "source": [
    "Let's also verify the number of evaluation images downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq3rW2wKWw1c"
   },
   "outputs": [],
   "source": [
    "# determine the number of evaluation data images\n",
    "len(fashion_mnist_eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucTxc7GGWw1c"
   },
   "source": [
    "## 4. Neural Network Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTQ_VZWaWw1d"
   },
   "source": [
    "In this section, we will implement the architecture of the **neural network** we aim to utilize to learn a model capable of classifying the 28x28 pixel FashionMNIST images of fashion items. However, before we start the implementation, let's briefly revisit the process to be established. The following cartoon provides a birds-eye view:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i5LlBmiWw1d"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 1000px\" src=\"./process.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyofP39KWw1d"
   },
   "source": [
    "### 4.1 Implementation of the Neural Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loUEinm1Ww1e"
   },
   "source": [
    "The neural network, which we name **'FashionMNISTNet'**, consists of three **fully-connected layers** (including an input layer and two hidden layers). Furthermore, the **FashionMNISTNet** should encompass the following number of neurons per layer: 100 (layer 1), 50 (layer 2), and 10 (layer 3). This means the first layer consists of 100 neurons, the second layer of 50 neurons, and the third layer of 10 neurons (corresponding to the number of digit classes we aim to classify)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGxSr-77Ww1e"
   },
   "source": [
    "We will now start implementing the network architecture as a separate Python class. Implementing the network architecture as a **separate class** in Python is good practice in deep learning projects. It will allow us to create and train several instances of the same neural network architecture. This provides us, for example, the opportunity to evaluate different initializations of the network parameters or train models using distinct datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLrELu2EWw1f"
   },
   "outputs": [],
   "source": [
    "# implement the MNISTNet network architecture\n",
    "class FashionMNISTNet(nn.Module):\n",
    "    \n",
    "    # define the class constructor\n",
    "    def __init__(self):\n",
    "        \n",
    "        # call super class constructor\n",
    "        super(FashionMNISTNet, self).__init__()\n",
    "        \n",
    "        # specify fully-connected (fc) layer 1 - in 28*28, out 100\n",
    "        self.linear1 = nn.Linear(28*28, 100, bias=True) # the linearity W*x+b\n",
    "        self.relu1 = nn.ReLU(inplace=True) # the non-linearity \n",
    "        \n",
    "        # specify fc layer 2 - in 100, out 50\n",
    "        self.linear2 = nn.Linear(100, 50, bias=True) # the linearity W*x+b\n",
    "        self.relu2 = nn.ReLU(inplace=True) # the non-linarity\n",
    "        \n",
    "        # specify fc layer 3 - in 50, out 10\n",
    "        self.linear3 = nn.Linear(50, 10, bias=True) # the linearity W*x+b\n",
    "        \n",
    "        # add a softmax to the last layer\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1) # the softmax\n",
    "        \n",
    "    # define network forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        # reshape image pixels\n",
    "        x = images.view(-1, 28*28)\n",
    "        \n",
    "        # define fc layer 1 forward pass\n",
    "        x = self.relu1(self.linear1(x))\n",
    "        \n",
    "        # define fc layer 2 forward pass\n",
    "        x = self.relu2(self.linear2(x))\n",
    "        \n",
    "        # define layer 3 forward pass\n",
    "        x = self.logsoftmax(self.linear3(x))\n",
    "        \n",
    "        # return forward pass result\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xy63DaNzWw1f"
   },
   "source": [
    "You may have noticed when reviewing the implementation above, that we applied an additional operator, referred to as **'Softmax'**, to the third layer of our neural network.\n",
    "\n",
    "The **softmax function**, also known as the normalized exponential function, takes as input a vector of K real numbers and normalizes it into a probability distribution consisting of K probabilities.\n",
    "\n",
    "That is, prior to applying softmax, some vector components could be negative or greater than one and might not sum to 1. However, after applying the softmax function, each component will be in the interval $(0,1)$, and the components will add up to 1, so they can be interpreted as probabilities. In general, the softmax function $\\sigma: \\mathbb {R} ^{K} \\to \\mathbb {R} ^{K}$ is defined by the formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5s_1Q7NWw1f"
   },
   "source": [
    "<center> $\\sigma (\\mathbf {z} )_{i}=\\ln ({e^{z_{i}} / \\sum _{j=1}^{K}e^{z_{j}}})$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9JtxNu4Ww1f"
   },
   "source": [
    "for $i = 1, â€¦, K$ and ${\\mathbf {z}}=(z_{1},\\ldots ,z_{K})\\in \\mathbb {R} ^{K}$ (Source: https://en.wikipedia.org/wiki/Softmax_function ). \n",
    "\n",
    "Let's have a look at the simplified three-class example below. The scores of the distinct predicted classes $c_i$ are computed from the forward propagation of the network. We then take the softmax and obtain the probabilities as shown:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ULWQ3RmWw1f"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 800px\" src=\"./softmax.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcrCZgZqWw1g"
   },
   "source": [
    "The output of the softmax function describes the neural network's probability (or confidence) that a particular sample belongs to a certain class. In the first example, the neural network assigns a confidence of 0.64 that it is a `shirt`, 0.04 that it is a `trouser`, and 0.29 that it is a `dress`. The same goes for each of the samples above.\n",
    "\n",
    "Now that we have implemented our first neural network, we are ready to instantiate a network model to be trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfvFFCCHWw1g"
   },
   "outputs": [],
   "source": [
    "model = FashionMNISTNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efX9IOPSw8DZ"
   },
   "source": [
    "Let's push the initialized `FashionMNISTNet` model to the enabled computing `device`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W93HbADVw8qe"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9j5xBQ2yxAMw"
   },
   "source": [
    "Let's also double-check if our model was deployed to the GPU if available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFGVBXGgxAo5"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yt4PtPLWw1g"
   },
   "source": [
    "Once the model is initialized, we can visualize the model structure and review the implemented network architecture by executing the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SF90-Nk1Ww1g"
   },
   "outputs": [],
   "source": [
    "# print the initialized architectures\n",
    "print('[LOG] FashionMNISTNet architecture:\\n\\n{}\\n'.format(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFKJMIjKWw1g"
   },
   "source": [
    "Does it look as intended? Brilliant! Finally, let's have a look at the number of model parameters that we aim to train in the next steps of the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFOWHzJ3Ww1h"
   },
   "outputs": [],
   "source": [
    "# init the number of model parameters\n",
    "num_params = 0\n",
    "\n",
    "# iterate over the distinct parameters\n",
    "for param in model.parameters():\n",
    "\n",
    "    # collect number of parameters\n",
    "    num_params += param.numel()\n",
    "    \n",
    "# print the number of model paramters\n",
    "print('[LOG] Number of to be trained FashionMNISTNet model parameters: {}.'.format(num_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY9rZQ7JWw1h"
   },
   "source": [
    "Ok, our \"simple\" FashionMNISTNet model already encompasses an impressive **84,060 model parameters** to be trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pytnqULPWw1h"
   },
   "source": [
    "### 4.2 Specification of the Neural Network Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHpHWQ7JWw1h"
   },
   "source": [
    "Now that we have implemented the **FashionMNISTNet**, we are ready to train the network. However, before starting the training, we need to define an appropriate loss function. Remember, we aim to train our model to learn a set of model parameters $\\theta$ that minimize the classification error between the true class $c^{i}$ of a given handwritten digit image $x^{i}$ and its predicted class $\\hat{c}^{i} = f_\\theta(x^{i})$ as accurately as possible. \n",
    "\n",
    "The training objective is to learn a set of optimal model parameters $\\theta^*$ that optimize $\\arg\\min_{\\theta} \\|C - f_\\theta(X)\\|$ over all training images in the FashionMNIST dataset. To achieve this optimization objective, we typically minimize a loss function $\\mathcal{L_{\\theta}}$ as part of the network training. In this lab, we use the **'Negative Log Likelihood (NLL)'** loss, defined by:\n",
    "\n",
    "<center> $\\mathcal{L}^{NLL}_{\\theta} (c_i, \\hat c_i) = - \\frac{1}{N} \\sum_{i=1}^N \\log (\\hat{c}_i) $, </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ID9HqJJqWw1h"
   },
   "source": [
    "for a set of $n$-FashionMNIST images $x^{i}$, $i=1,...,n$ and their respective predicted class labels $\\hat{c}^{i}$. This is summed for all the correct classes. \n",
    "\n",
    "Let's have a look at a brief example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xRWCsbrWw1i"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 900px\" src=\"./loss.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcObuMZfWw1i"
   },
   "source": [
    "During training, the **NLL** loss will penalize models that result in a high classification error between the predicted class labels $\\hat{c}^{i}$ and their respective true class label $c^{i}$. Fortunately, implementing the NLL loss is already available in `PyTorch`! It can be instantiated \"off-the-shelf\" with the following `PyTorch` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbgFFIDjWw1i"
   },
   "outputs": [],
   "source": [
    "# define the optimization criterion / loss function\n",
    "nll_loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbspDM2dxGrO"
   },
   "source": [
    "Let's also push the initialized `nll_loss` computation to the enabled computing `device`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgKeoEcaxIdB"
   },
   "outputs": [],
   "source": [
    "nll_loss = nll_loss.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJhKTaHnWw1i"
   },
   "source": [
    "## 5. Neural Network Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRwd3R8XWw1i"
   },
   "source": [
    "In this section, we will train our neural network model (as implemented in the section above) using the transformed images of fashion items. More specifically, we will examine the distinct training steps and how to monitor the training progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKbH8GgrWw1i"
   },
   "source": [
    "### 5.1. Preparing the Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1K23pmmEWw1j"
   },
   "source": [
    "So far, we have pre-processed the dataset, implemented the ANN and defined the classification error. Let's now start to train a corresponding model for **20 epochs** and a **mini-batch size of 128** FashionMNIST images per batch. This implies that the whole dataset will be fed to the ANN 20 times in chunks of 128 images yielding to **469 mini-batches** (60.000 images / 128 images per mini-batch) per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bMEnxc1Ww1j"
   },
   "outputs": [],
   "source": [
    "# specify the training parameters\n",
    "num_epochs = 20 # number of training epochs\n",
    "mini_batch_size = 128 # size of the mini-batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jX99_DY7Ww1j"
   },
   "source": [
    "Based on the loss magnitude of a certain mini-batch, PyTorch automatically computes the gradients. Moreover, the library also assists in optimizing and updating the network parameters $ theta$ based on the gradient.\n",
    "\n",
    "We will use **Stochastic Gradient Descent (SGD) optimization** and set the learning rate $l = 0.001$. With each mini-batch step, the optimizer will update the model parameters $\\theta$ values according to the degree of classification error (the MSE loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84Oq2woEWw1j"
   },
   "outputs": [],
   "source": [
    "# define learning rate and optimization strategy\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HX8MBSDxWw1k"
   },
   "source": [
    "Now that we have successfully implemented and defined the three ANN building blocks, let's review the `FashionMNISTNet` model definition and the `loss`. Please read the above code and comments carefully, and don't hesitate to ask any questions you might have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XO1P2wb3Ww1k"
   },
   "source": [
    "Additionally, let's specify and instantiate a corresponding PyTorch data loader that feeds the image tensors to our neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyLwFEMXWw1l"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_train_dataloader = torch.utils.data.DataLoader(fashion_mnist_train_data, batch_size=mini_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tp6hmrg7Ww1l"
   },
   "source": [
    "### 5.2. Running the Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ov5Z6NLvWw1m"
   },
   "source": [
    "Finally, we start training the model. The detailed training procedure for each mini-batch is as follows:\n",
    "\n",
    ">1. Do a forward pass through the FashionMNISTNet network, \n",
    ">2. Compute the negative log likelihood classification error $\\mathcal{L}^{NLL}_{\\theta}(c^{i};\\hat{c}^{i})$, \n",
    ">3. Do a backward pass through the FashionMNISTNet network, and \n",
    ">4. Update the parameters of the network $f_\\theta(\\cdot)$.\n",
    "\n",
    "We will monitor whether the loss decreases as training progresses to ensure learning while training our ANN model. Therefore, we will evaluate the classification performance of our model on a small set of test images after every epoch.\n",
    "\n",
    "The following elements of the network training code below should be given particular attention:\n",
    " \n",
    ">- `loss.backward()` computes the gradients based on the magnitude of the reconstruction loss,\n",
    ">- `optimizer.step()` updates the network parameters based on the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70W8AZWlWw1m"
   },
   "outputs": [],
   "source": [
    "# init collection of training epoch losses\n",
    "train_epoch_losses = []\n",
    "\n",
    "# set the model in training mode\n",
    "model.train()\n",
    "\n",
    "# train the MNISTNet model\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # init collection of mini-batch losses\n",
    "    train_mini_batch_losses = []\n",
    "    \n",
    "    # iterate over all-mini batches\n",
    "    for i, (images, labels) in enumerate(fashion_mnist_train_dataloader):\n",
    "        \n",
    "        # push mini-batch data to computation device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # run forward pass through the network\n",
    "        output = model(images)\n",
    "        \n",
    "        # reset graph gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # determine classification loss\n",
    "        loss = nll_loss(output, labels)\n",
    "        \n",
    "        # run backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update network paramaters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # collect mini-batch reconstruction loss\n",
    "        train_mini_batch_losses.append(loss.data.item())\n",
    "    \n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_loss = np.mean(train_mini_batch_losses)\n",
    "    \n",
    "    # print epoch loss\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "    print('[LOG {}] epoch: {} train-loss: {}'.format(str(now), str(epoch), str(train_epoch_loss)))\n",
    "    \n",
    "    # set filename of actual model\n",
    "    model_name = 'fashion_mnist_model_epoch_{}.pth'.format(str(epoch))\n",
    "\n",
    "    # save current model to GDrive models directory\n",
    "    torch.save(model.state_dict(), os.path.join(models_directory, model_name))\n",
    "    \n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_losses.append(train_epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dqoGo_7Ww1m"
   },
   "source": [
    "Upon successful training, let's visualize and inspect the  training loss observable per epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLI0Y53VWw1m"
   },
   "outputs": [],
   "source": [
    "# prepare plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# add grid\n",
    "ax.grid(linestyle='dotted')\n",
    "\n",
    "# plot the training epochs vs. the epochs' classification error\n",
    "ax.plot(np.array(range(1, len(train_epoch_losses)+1)), train_epoch_losses, label='epoch loss (blue)')\n",
    "\n",
    "# add axis legends\n",
    "ax.set_xlabel(\"[training epoch $e_i$]\", fontsize=10)\n",
    "ax.set_ylabel(\"[Classification Error $\\mathcal{L}^{NLL}$]\", fontsize=10)\n",
    "\n",
    "# set plot legend\n",
    "plt.legend(loc=\"upper right\", numpoints=1, fancybox=True)\n",
    "\n",
    "# add plot title\n",
    "plt.title('Training Epochs $e_i$ vs. Classification Error $L^{NLL}$', fontsize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmkQMB6YWw1n"
   },
   "source": [
    "Ok, fantastic. The training error is nicely going down. We could train the network a couple more epochs until the error converges. But let's stay with the 20 training epochs for now and continue with evaluating our trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nyWq1X-Ww1n"
   },
   "source": [
    "## 6. Neural Network Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7-GBxuwWw1n"
   },
   "source": [
    "Before evaluating our model, let's load the best performing model. Remember that we stored a snapshot of the model after each training epoch in our local model directory. We will now load the last snapshot saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-w1B1k_NWw1n"
   },
   "outputs": [],
   "source": [
    "# restore pre-trained model snapshot\n",
    "best_model_name = 'https://raw.githubusercontent.com/HSG-AIML-Teaching/GSERM2024-Lab/master/lab_04/models/fashion_mnist_model_epoch_19.pth'\n",
    "\n",
    "# read stored model from the remote location\n",
    "model_bytes = urllib.request.urlopen(best_model_name)\n",
    "\n",
    "# load model tensor from io.BytesIO object\n",
    "model_buffer = io.BytesIO(model_bytes.read())\n",
    "\n",
    "# init pre-trained model class\n",
    "best_model = FashionMNISTNet()\n",
    "\n",
    "# load pre-trained models\n",
    "best_model.load_state_dict(torch.load(model_buffer, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oqOeiajWw1n"
   },
   "source": [
    "Let's inspect if the model was loaded successfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KarjZ3ldWw1n"
   },
   "outputs": [],
   "source": [
    "# set model in evaluation mode\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaFA9LyRWw1o"
   },
   "source": [
    "To evaluate our trained model, we need to feed the FashionMNIST images reserved for evaluation (the images that we didn't use as part of the training process) through the model. Therefore, let's again define a corresponding PyTorch data loader that feeds the image tensors to our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQB-RFR8Ww1o"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_eval_dataloader = torch.utils.data.DataLoader(fashion_mnist_eval_data, batch_size=10000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPP7OowBWw1o"
   },
   "source": [
    "We will now evaluate the trained model using the same mini-batch approach as we did during network training and derive the mean negative log-likelihood loss of the mini-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpttWy_AWw1o"
   },
   "outputs": [],
   "source": [
    "# init collection of mini-batch losses\n",
    "eval_mini_batch_losses = []\n",
    "\n",
    "# iterate over all-mini batches\n",
    "for i, (images, labels) in enumerate(fashion_mnist_eval_dataloader):\n",
    "\n",
    "    # run forward pass through the network\n",
    "    output = best_model(images)\n",
    "\n",
    "    # determine classification loss\n",
    "    loss = nll_loss(output, labels)\n",
    "\n",
    "    # collect mini-batch reconstruction loss\n",
    "    eval_mini_batch_losses.append(loss.data.item())\n",
    "\n",
    "# determine mean min-batch loss of epoch\n",
    "eval_loss = np.mean(eval_mini_batch_losses)\n",
    "\n",
    "# print epoch loss\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] eval-loss: {}'.format(str(now), str(eval_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNwLBDGPWw1p"
   },
   "source": [
    "understandGreat, the evaluation loss aligns with our training loss. Let's inspect a few sample predictions to get an impression of the model's quality. We will pick a random image from our evaluation dataset and retrieve its `PyTorch` tensor and the corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTM5mTHaWw1p"
   },
   "outputs": [],
   "source": [
    "# set (random) image id\n",
    "image_id = 2000\n",
    "\n",
    "# retrieve image exhibiting the image id\n",
    "fashion_mnist_eval_image, fashion_mnist_eval_label = fashion_mnist_eval_data[image_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkZowxdUWw1p"
   },
   "source": [
    "Let's now inspect the true class of the selected image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIq9uSnfWw1q"
   },
   "outputs": [],
   "source": [
    "fashion_classes[fashion_mnist_eval_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hjz4GOpyWw1q"
   },
   "source": [
    "The randomly selected image should contain a bag. Let's inspect the image accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1hZMQ6oWw1r"
   },
   "outputs": [],
   "source": [
    "# define tensor to image transformation\n",
    "trans = torchvision.transforms.ToPILImage()\n",
    "\n",
    "# set image plot title \n",
    "plt.title('Example: {}, Label: {}'.format(str(image_id), fashion_classes[fashion_mnist_eval_label]))\n",
    "\n",
    "# plot mnist handwritten digit sample\n",
    "plt.imshow(trans(fashion_mnist_eval_image), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFW-PYEnWw1r"
   },
   "source": [
    "Let's compare the true label with our model's prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfaV80IpWw1s"
   },
   "outputs": [],
   "source": [
    "best_model(fashion_mnist_eval_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNFAM_deWw1s"
   },
   "source": [
    "We can even determine the likelihood of the most probable class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2knLiUqWw1t"
   },
   "outputs": [],
   "source": [
    "most_probable = torch.argmax(best_model(fashion_mnist_eval_image), dim=1).item()\n",
    "print('Most probable class: {}'.format(most_probable))\n",
    "print('This class represents the following fashion article: {}'.format(fashion_classes[most_probable]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwOIf2adWw1t"
   },
   "source": [
    "Let's now obtain the predictions for all the fashion item images in the evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRmjfYDZWw1t"
   },
   "outputs": [],
   "source": [
    "predictions = torch.argmax(best_model(fashion_mnist_eval_data.data.float()), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFKiMKw-Ww1t"
   },
   "source": [
    "Furthermore, let's calculate the overall classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvV-HLcsWw1t"
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(fashion_mnist_eval_data.targets, predictions.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6B-KdgKNWw1u"
   },
   "source": [
    "Let's also inspect the **confusion matrix** to identify major sources of misclassification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5LkSBwpWw1u"
   },
   "outputs": [],
   "source": [
    "# determine classification matrix of the predicted and target classes\n",
    "mat = confusion_matrix(fashion_mnist_eval_data.targets, predictions.detach())\n",
    "\n",
    "# initialize the plot and define size\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# plot corresponding confusion matrix\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, cmap='YlOrRd_r', xticklabels=fashion_classes.values(), yticklabels=fashion_classes.values())\n",
    "plt.tick_params(axis='both', which='major', labelsize=8, labelbottom = False, bottom=False, top = False, left = False, labeltop=True)\n",
    "\n",
    "# set plot title\n",
    "plt.title('Fashion MNIST classification matrix')\n",
    "\n",
    "# set axis labels\n",
    "plt.xlabel('[true label]')\n",
    "plt.ylabel('[predicted label]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ob6vR-e3Ww1u"
   },
   "source": [
    "Our current model **confuses sandals** with either **sneakers** or **ankle boots**. However, the inverse does not hold. The model sometimes confuses sneakers with ankle boots and rarely with sandals. The same holds for ankle boots. Our model also has issues distinguishing shirts from coats (and, to a lesser degree, from T-shirts and pullovers). These mistakes may not be surprising, as these items exhibit high similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1l8HbUzWw1v"
   },
   "source": [
    "## 7. Lab Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3P5e48aWw1w"
   },
   "source": [
    "In this lab, you successfully accomplished the following key learnings:\n",
    "\n",
    "> 1. **Understanding Neural Network Design:** Mastered artificial neural networks' fundamental concepts and architectural design, enhancing your comprehension of deep learning models.\n",
    "> 2. **Model Implementation and Training:** Developed practical skills in implementing and training a neural network model using PyTorch, applying it to the Fashion-MNIST dataset to predict class labels.\n",
    "> 3. **Evaluating Model Performance:** Gained expertise in evaluating the performance of neural network models through metrics such as loss and accuracy, and through the construction and analysis of confusion matrices.\n",
    "\n",
    "This lab provided insights into designing, implementing, training, and evaluating neural networks for image classification. It equipped you with essential tools and techniques for effective model building, evaluation, and application. These skills are invaluable for succeeding in deep learning."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "aut1dJXmWw1O",
    "Ks081EJEWw1P",
    "vyqnqndjWw1S",
    "ucTxc7GGWw1c",
    "hJhKTaHnWw1i",
    "8nyWq1X-Ww1n",
    "e1l8HbUzWw1v"
   ],
   "name": "lab_04.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
